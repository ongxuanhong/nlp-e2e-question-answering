{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "import evaluate\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sử dụng mô hình \"distilbert-base-uncased\"\n",
    "# làm mô hình checkpoint\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "\n",
    "# Độ dài tối đa cho mỗi đoạn văn bản\n",
    "# sau khi được xử lý\n",
    "MAX_LENGTH = 384\n",
    "\n",
    "# Khoảng cách giữa các điểm bắt đầu\n",
    "# của các đoạn văn bản liên tiếp\n",
    "STRIDE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download squad dataset từ HuggingFace\n",
    "DATASET_NAME = \"squad_v2\"\n",
    "raw_datasets = load_dataset(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be85543aeaaa14008c9063',\n",
       " 'title': 'Beyoncé',\n",
       " 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       " 'question': 'When did Beyonce start becoming popular?',\n",
       " 'answers': {'text': ['in the late 1990s'], 'answer_start': [269]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = raw_datasets[\"train\"][0]\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongong/anaconda3/envs/nlp-e2e-question-answering/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer để run một số example\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa hàm preprocess_training_examples và nhận đối số examples là dữ liệu đào tạo\n",
    "def preprocess_training_examples(examples):\n",
    "    # Trích xuất danh sách câu hỏi từ examples và\n",
    "    # loại bỏ các khoảng trắng dư thừa\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "\n",
    "    # Tiến hành mã hóa thông tin đầu vào sử dụng tokenizer\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=\"only_second\",\n",
    "        stride=STRIDE,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Trích xuất offset_mapping từ inputs và loại bỏ nó ra khỏi inputs\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "\n",
    "    # Trích xuất sample_map từ inputs và loại bỏ nó ra khỏi inputs\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # Trích xuất thông tin về câu trả lời (answers) từ examples\n",
    "    answers = examples[\"answers\"]\n",
    "\n",
    "    # Khởi tạo danh sách các vị trí bắt đầu và kết thúc câu trả lời\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    # Duyệt qua danh sách offset_mapping\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        # Xác định index của mẫu (sample) liên quan đến offset hiện tại\n",
    "        sample_idx = sample_map[i]\n",
    "\n",
    "        # Trích xuất sequence_ids từ inputs\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Xác định vị trí bắt đầu và kết thúc của ngữ cảnh\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # Trích xuất thông tin về câu trả lời cho mẫu này\n",
    "        answer = answers[sample_idx]\n",
    "\n",
    "        if len(answer[\"text\"]) == 0:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Xác định vị trí ký tự bắt đầu và kết thúc của câu trả lời\n",
    "            # trong ngữ cảnh\n",
    "            start_char = answer[\"answer_start\"][0]\n",
    "            end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "\n",
    "            # Nếu câu trả lời không nằm hoàn toàn trong ngữ cảnh,\n",
    "            # gán nhãn là (0, 0)\n",
    "            if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "                start_positions.append(0)\n",
    "                end_positions.append(0)\n",
    "            else:\n",
    "                # Nếu không, gán vị trí bắt đầu và kết thúc dựa trên\n",
    "                # vị trí của các mã thông tin\n",
    "                idx = context_start\n",
    "                while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                    idx += 1\n",
    "                start_positions.append(idx - 1)\n",
    "\n",
    "                idx = context_end\n",
    "                while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                    idx -= 1\n",
    "                end_positions.append(idx + 1)\n",
    "\n",
    "    # Thêm thông tin vị trí bắt đầu và kết thúc vào inputs\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d96079071f44ab1bdc1ee3b4072685f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/130319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(130319, 131754)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tạo một biến train_dataset và gán cho nó giá trị sau khi áp dụng hàm preprocess_training_examples lên tập dữ liệu \"train\"\n",
    "# Bật chế độ xử lý theo từng batch bằng cách đặt batched=True\n",
    "# Loại bỏ các cột không cần thiết trong tập dữ liệu \"train\" bằng cách sử dụng remove_columns\n",
    "\n",
    "train_dataset = raw_datasets[\"train\"].map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "# In ra độ dài của tập dữ liệu \"train\" ban đầu và độ dài của tập dữ liệu đã được xử lý (train_dataset)\n",
    "len(raw_datasets[\"train\"]), len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'start_positions', 'end_positions'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the first example in the train_dataset\n",
    "train_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    # Chuẩn bị danh sách câu hỏi bằng cách\n",
    "    # loại bỏ khoảng trắng ở đầu và cuối mỗi câu hỏi\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "\n",
    "    # Sử dụng tokenizer để mã hóa các câu hỏi và văn bản liên quan\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=\"only_second\",\n",
    "        stride=STRIDE,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Lấy ánh xạ để ánh xạ lại ví dụ tham chiếu cho từng dòng trong inputs\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    # Xác định ví dụ tham chiếu cho mỗi dòng đầu vào và điều chỉnh ánh xạ offset\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "\n",
    "        # Loại bỏ các offset không phù hợp với sequence_ids\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None\n",
    "            for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    # Thêm thông tin ví dụ tham chiếu vào đầu vào\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d10d19710246219d7e94b7a88327d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11873 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(11873, 12134)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tạo một biến validation_dataset và gán giá trị bằng việc sử dụng dữ liệu từ raw_datasets[\"validation\"] sau khi áp dụng một hàm xử lý trước.\n",
    "validation_dataset = raw_datasets[\"validation\"].map(\n",
    "    preprocess_validation_examples,  # Gọi hàm preprocess_validation_examples để xử lý dữ liệu đầu vào.\n",
    "    batched=True,  # Xử lý dữ liệu theo từng batch.\n",
    "    remove_columns=raw_datasets[\"validation\"].column_names,  # Loại bỏ các cột không cần thiết từ dữ liệu ban đầu.\n",
    ")\n",
    "\n",
    "# In ra độ dài của raw_datasets[\"validation\"] và validation_dataset để so sánh.\n",
    "len(raw_datasets[\"validation\"]), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongong/anaconda3/envs/nlp-e2e-question-answering/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo đối tượng args là các tham số cho quá trình huấn luyện\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"distilbert-finetuned-squadv2\",\n",
    "    evaluation_strategy=\"no\", # Chế độ đánh giá không tự động sau mỗi epoch\n",
    "    save_strategy=\"epoch\", # Lưu checkpoint sau mỗi epoch\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True, # Sử dụng kiểu dữ liệu half-precision để tối ưu tài nguyên\n",
    "    # push_to_hub=True, # Đẩy kết quả huấn luyện lên HuggingFace Hub\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongong/anaconda3/envs/nlp-e2e-question-answering/lib/python3.10/site-packages/accelerate/accelerator.py:449: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo một đối tượng Trainer để huấn luyện mô hình\n",
    "trainer = Trainer(\n",
    "    model=model,  # Sử dụng mô hình đã tạo trước đó\n",
    "    args=args,  # Các tham số và cấu hình huấn luyện\n",
    "    train_dataset=train_dataset,  # Sử dụng tập dữ liệu huấn luyện\n",
    "    eval_dataset=validation_dataset,  # Sử dụng tập dữ liệu đánh giá\n",
    "    tokenizer=tokenizer,  # Sử dụng tokenizer để xử lý văn bản\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11221' max='49410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11221/49410 22:07 < 1:15:20, 8.45 it/s, Epoch 0.68/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.118800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.248700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.029200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.823200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.716300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.638700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.562100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.538300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.506500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.461300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.427100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.402100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.414500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.407600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.348200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.321800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.306100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.292500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.266300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.289100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.296400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# Bắt đầu quá trình huấn luyện\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gửi dữ liệu đào tạo lên Hub\n",
    "# trainer.push_to_hub(commit_message=\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải metric \"squad\" từ thư viện evaluate\n",
    "metric = evaluate.load(\"squad_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BEST = 20 # Số lượng kết quả tốt nhất được lựa chọn sau khi dự đoán\n",
    "MAX_ANS_LENGTH = 30 # Độ dài tối đa cho câu trả lời dự đoán\n",
    "\n",
    "def compute_metrics(start_logits, end_logits, features, examples):\n",
    "    # Tạo một từ điển mặc định để ánh xạ mỗi ví dụ với danh sách các đặc trưng tương ứng\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_to_features[feature['example_id']].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example['id']\n",
    "        context = example['context']\n",
    "        answers = []\n",
    "\n",
    "        # Lặp qua tất cả các đặc trưng liên quan đến ví dụ đó\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index]['offset_mapping']\n",
    "\n",
    "            # Lấy các chỉ số có giá trị lớn nhất cho start và end logits\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -N_BEST - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -N_BEST - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Bỏ qua các câu trả lời không hoàn toàn nằm trong ngữ cảnh\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Bỏ qua các câu trả lời có độ dài > max_answer_length\n",
    "                    if end_index - start_index + 1 > MAX_ANS_LENGTH:\n",
    "                        continue\n",
    "\n",
    "                    # Tạo một câu trả lời mới\n",
    "                    answer = {\n",
    "                        'text': context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        'logit_score': start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # Chọn câu trả lời có điểm số tốt nhất\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x['logit_score'])\n",
    "            answer_dict = {\n",
    "                'id': example_id,\n",
    "                'prediction_text': best_answer['text'],\n",
    "                'no_answer_probability': 1 - best_answer['logit_score']\n",
    "            }\n",
    "        else:\n",
    "            answer_dict = {\n",
    "                'id': example_id,\n",
    "                'prediction_text': '',\n",
    "                'no_answer_probability': 1.0\n",
    "            }\n",
    "        predicted_answers.append(answer_dict)\n",
    "\n",
    "    # Tạo danh sách câu trả lời lý thuyết từ các ví dụ\n",
    "    theoretical_answers = [\n",
    "        {'id': ex['id'], 'answers': ex['answers']} for ex in examples\n",
    "    ]\n",
    "    # Sử dụng metric.compute để tính toán các độ đo và trả về kết quả\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thực hiện dự đoán trên tập dữ liệu validation\n",
    "predictions, _, _ = trainer.predict(validation_dataset)\n",
    "\n",
    "# Lấy ra thông tin về các điểm bắt đầu và điểm kết thúc của câu trả lời dự đoán\n",
    "start_logits, end_logits = predictions\n",
    "\n",
    "# Tính toán các chỉ số đánh giá sử dụng hàm compute_metrics\n",
    "results = compute_metrics(\n",
    "    start_logits,\n",
    "    end_logits,\n",
    "    validation_dataset,\n",
    "    raw_datasets[\"validation\"]\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model from Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "PIPELINE_NAME = 'question-answering'\n",
    "MODEL_NAME = 'hongong/distilbert-finetuned-squadv2'\n",
    "pipe = pipeline(PIPELINE_NAME, model=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_QUESTION = 'where is the highest mountain in solar system located'\n",
    "INPUT_CONTEXT = 'The highest mountain and volcano in the Solar System is on the planet Mars. It is called Olympus Mons and is 16 miles (24 kilometers) high which makes it about three times higher than Mt. Everest.'\n",
    "pipe(question=INPUT_QUESTION, context=INPUT_CONTEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-e2e-question-answering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
