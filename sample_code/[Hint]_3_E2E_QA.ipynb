{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## **1. Install and import bibraries**"],"metadata":{"id":"5C8jXzW55vTV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"D87uLZ8hvQZu"},"outputs":[],"source":["!pip install -qq transformers[sentencepiece]==4.35.2 datasets==2.16.1 evaluate==0.4.1"]},{"cell_type":"code","source":["!sudo apt-get install libomp-dev\n","!pip install -qq faiss-gpu"],"metadata":{"id":"byx40gtgqhxv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import collections\n","import torch\n","import faiss\n","import evaluate\n","\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModel\n","from transformers import AutoModelForQuestionAnswering\n","from transformers import TrainingArguments\n","from transformers import Trainer\n","from tqdm.auto import tqdm\n","\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"],"metadata":{"id":"4GAgtobPvWRz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **2. Download dataset**"],"metadata":{"id":"BSzModVq5wx2"}},{"cell_type":"code","source":["DATASET_NAME = None\n","raw_datasets = None\n","raw_datasets"],"metadata":{"id":"u4MXZs4gborS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **3. Filter out non-answerable samples**"],"metadata":{"id":"qr66b79mBr0p"}},{"cell_type":"code","source":["raw_datasets = None\n","raw_datasets"],"metadata":{"id":"n5vTWVlVeB3N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["columns = raw_datasets.column_names\n","columns_to_keep = ['id', 'context', 'question', 'answers']\n","columns_to_remove = set(columns_to_keep).symmetric_difference(columns)\n","raw_datasets = raw_datasets.remove_columns(columns_to_remove)\n","raw_datasets"],"metadata":{"id":"bFCgdH2EJbtL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **4. Intialize pre-trained model**"],"metadata":{"id":"zincwHoGBybN"}},{"cell_type":"code","source":["MODEL_NAME = None\n","tokenizer = None\n","model = None"],"metadata":{"id":"cMWwq2zSe-VP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **5. Create get vector embedding functions**"],"metadata":{"id":"ZjbRxzyJB2Ne"}},{"cell_type":"code","source":["def cls_pooling(model_output):\n","    return None"],"metadata":{"id":"F5xDasEbi11B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_embeddings(text_list):\n","\n","    return None"],"metadata":{"id":"1gWOz8ydB_u7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test functionality\n","embedding = get_embeddings(raw_datasets['question'][0])\n","embedding.shape"],"metadata":{"id":"zuuKufCvjk-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert to numpy array (required for HF Datasets)\n","EMBEDDING_COLUMN = 'question_embedding'\n","embeddings_dataset = raw_datasets.map(\n","    lambda x: {EMBEDDING_COLUMN: get_embeddings(x['question']).detach().cpu().numpy()[0]}\n",")"],"metadata":{"id":"kbAf9wREjlIf","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeddings_dataset.add_faiss_index(column=EMBEDDING_COLUMN)"],"metadata":{"id":"8qj8CqgRj4MK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeddings_dataset[0]"],"metadata":{"id":"QphWLT8ZvmKf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **6. Search similar samples with a question**"],"metadata":{"id":"VWxok5dWCBZZ"}},{"cell_type":"code","source":["input_question = 'When did Beyonce start becoming popular?'\n","\n","input_quest_embedding = get_embeddings([input_question]).cpu().detach().numpy()\n","input_quest_embedding.shape"],"metadata":{"id":"q3BR6BlzkxJv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TOP_K = 5\n","scores, samples = embeddings_dataset.get_nearest_examples(\n","    EMBEDDING_COLUMN, input_quest_embedding, k=TOP_K\n",")"],"metadata":{"id":"SxniawBtlCMv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for idx, score in enumerate(scores):\n","    print(f'Top {idx + 1}\\tScore: {score}')\n","    print(f'Question: {samples[\"question\"][idx]}')\n","    print(f'Context: {samples[\"context\"][idx]}')\n","    print()"],"metadata":{"id":"D0Y2e6H62vdy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **7. QA**"],"metadata":{"id":"bMyhiEuJJsnL"}},{"cell_type":"code","source":["from transformers import pipeline\n","\n","PIPELINE_NAME = None\n","MODEL_NAME = None\n","pipe = pipeline(PIPELINE_NAME, model=MODEL_NAME)"],"metadata":{"id":"sz4E-6PaJvct"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'Input question: {input_question}')\n","for idx, score in enumerate(scores):\n","    context = samples[\"context\"][idx]\n","    answer = pipe(\n","        question=input_question,\n","        context=context\n","    )\n","    print(f'Top {idx + 1}\\tScore: {score}')\n","    print(f'Context: {context}')\n","    print(f'Answer: {answer}')\n","    print()"],"metadata":{"id":"PSFzFqQiJoij"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_datasets = load_dataset(DATASET_NAME, split='validation')\n","test_datasets"],"metadata":{"id":"ncH2IwVdTtZi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TOP_K = 3\n","for idx, input_question in enumerate(embeddings_dataset['question'][200:210]):\n","    input_quest_embedding = get_embeddings([input_question]).cpu().detach().numpy()\n","    scores, samples = embeddings_dataset.get_nearest_examples(\n","        EMBEDDING_COLUMN, input_quest_embedding, k=TOP_K\n","    )\n","    print(f'Question {idx + 1}: {input_question}')\n","    for jdx, score in enumerate(scores):\n","        print(f'Top {jdx + 1}\\tScore: {score}')\n","        context = samples['context'][jdx]\n","        answer = pipe(\n","            question=input_question,\n","            context=context\n","        )\n","        print(f'Context: {context}')\n","        print(f'Answer: {answer}')\n","        print()\n","    print()"],"metadata":{"id":"gHdhM_I3T1ev"},"execution_count":null,"outputs":[]}]}